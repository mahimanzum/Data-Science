{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "readpath0 = 'C:/Users/HP/Desktop/Data Science/data/A/*jpg'\n",
    "readpath1 = 'C:/Users/HP/Desktop/Data Science/data/B/*jpg'\n",
    "labels = 'C:/Users/HP/Desktop/Data Science/data/labels.csv'\n",
    "objectClass0 = 'A'\n",
    "objectClass1 = 'B'\n",
    "\n",
    "images = glob.glob(readpath0)\n",
    "labelfile = open(labels,'w')\n",
    "\n",
    "for image in images:\n",
    "    labelfile.write(image+','+objectClass0+'\\n')\n",
    "images = glob.glob(readpath1)\n",
    "for image in images:\n",
    "    labelfile.write(image+','+objectClass1+'\\n')\n",
    "labelfile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "labels = 'C:/Users/HP/Desktop/Data Science/data/labels.csv'\n",
    "shuffled_labels = 'C:/Users/HP/Desktop/Data Science/data/shuffled_labels.csv'\n",
    "\n",
    "labelfile = open(labels, \"r\")\n",
    "lines = labelfile.readlines()\n",
    "labelfile.close()\n",
    "random.shuffle(lines)\n",
    "\n",
    "shufflefile = open(shuffled_labels, \"w\")\n",
    "shufflefile.writelines(lines)\n",
    "shufflefile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "\n",
    "labels = 'C:/Users/HP/Desktop/Data Science/data/shuffled_labels.csv'\n",
    "npzfile = 'C:/Users/HP/Desktop/Data Science/data/labels.npz'\n",
    "\n",
    "df = pandas.read_csv(labels)\n",
    "\n",
    "rows = df.iterrows()\n",
    "\n",
    "X_temp = []\n",
    "Y_temp = []\n",
    "\n",
    "for row in rows:\n",
    "    image = row[1][0]\n",
    "    img = cv2.imread(image)\n",
    "    img = cv2.resize(img,(32,32))\n",
    "    imageClass = row[1][1]\n",
    "    X_temp.append(img)\n",
    "    Y_temp.append(imageClass)\n",
    "\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y_temp)\n",
    "encoded_Y = encoder.transform(Y_temp)\n",
    "Y = np_utils.to_categorical(encoded_Y)\n",
    "\n",
    "np.savez(npzfile, X_train=X_temp,Y_train=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(99, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Flatten\n",
    "from keras.layers.convolutional import Convolution2D,MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "num_classes = 2\n",
    "\n",
    "\n",
    "#npzfile = 'H:/Workshop/Lecture Plan/Lecture 6/Labels/labels.npz'\n",
    "\n",
    "dataset =  np.load(npzfile)\n",
    "x_train = dataset['X_train']\n",
    "y_train = dataset['Y_train']\n",
    "print(type(x_train))\n",
    "x_train = x_train/255\n",
    "print(x_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\envs\\workshop\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (5, 5), input_shape=(32, 32, 3..., activation=\"relu\", padding=\"valid\")`\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 32)        2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               802944    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 805,634\n",
      "Trainable params: 805,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\envs\\workshop\\lib\\site-packages\\keras\\models.py:874: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 79 samples, validate on 20 samples\n",
      "Epoch 1/20\n",
      " - 2s - loss: 1.0206 - acc: 0.5570 - val_loss: 1.0353 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      " - 0s - loss: 0.9772 - acc: 0.4937 - val_loss: 0.6800 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.6430 - acc: 0.6203 - val_loss: 0.7059 - val_acc: 0.5500\n",
      "Epoch 4/20\n",
      " - 0s - loss: 0.6490 - acc: 0.5570 - val_loss: 0.6765 - val_acc: 0.5500\n",
      "Epoch 5/20\n",
      " - 2s - loss: 0.6019 - acc: 0.7089 - val_loss: 0.6204 - val_acc: 0.8000\n",
      "Epoch 6/20\n",
      " - 0s - loss: 0.5606 - acc: 0.8101 - val_loss: 0.5809 - val_acc: 0.7000\n",
      "Epoch 7/20\n",
      " - 0s - loss: 0.4747 - acc: 0.8861 - val_loss: 0.5491 - val_acc: 0.8000\n",
      "Epoch 8/20\n",
      " - 0s - loss: 0.3994 - acc: 0.9241 - val_loss: 0.5050 - val_acc: 0.7000\n",
      "Epoch 9/20\n",
      " - 0s - loss: 0.3138 - acc: 0.9494 - val_loss: 0.5089 - val_acc: 0.6500\n",
      "Epoch 10/20\n",
      " - 1s - loss: 0.3278 - acc: 0.8734 - val_loss: 0.4096 - val_acc: 0.8500\n",
      "Epoch 11/20\n",
      " - 1s - loss: 0.2168 - acc: 0.9494 - val_loss: 0.3773 - val_acc: 0.8500\n",
      "Epoch 12/20\n",
      " - 0s - loss: 0.1753 - acc: 0.9747 - val_loss: 0.2951 - val_acc: 0.9000\n",
      "Epoch 13/20\n",
      " - 0s - loss: 0.1343 - acc: 1.0000 - val_loss: 0.2552 - val_acc: 0.9000\n",
      "Epoch 14/20\n",
      " - 1s - loss: 0.1078 - acc: 0.9873 - val_loss: 0.2393 - val_acc: 0.8500\n",
      "Epoch 15/20\n",
      " - 0s - loss: 0.0766 - acc: 1.0000 - val_loss: 0.1885 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      " - 0s - loss: 0.0641 - acc: 1.0000 - val_loss: 0.1992 - val_acc: 0.8500\n",
      "Epoch 17/20\n",
      " - 0s - loss: 0.0431 - acc: 1.0000 - val_loss: 0.1936 - val_acc: 0.8500\n",
      "Epoch 18/20\n",
      " - 0s - loss: 0.0305 - acc: 1.0000 - val_loss: 0.1537 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      " - 0s - loss: 0.0272 - acc: 1.0000 - val_loss: 0.1495 - val_acc: 0.9500\n",
      "Epoch 20/20\n",
      " - 0s - loss: 0.0170 - acc: 1.0000 - val_loss: 0.1824 - val_acc: 0.8500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27f8674ea20>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Flatten\n",
    "from keras.layers.convolutional import Convolution2D,MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "\n",
    "def CNN_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, 5, 5, border_mode= 'valid' , input_shape=(32,32,3),activation= 'relu' ))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation= 'relu' ))\n",
    "    model.add(Dense(num_classes, activation= 'softmax' ))\n",
    "    # Compile model\n",
    "    model.compile(loss= 'categorical_crossentropy' , optimizer= 'adam' , metrics=[ 'accuracy' ])\n",
    "    return model\n",
    "\n",
    "model = CNN_model()\n",
    "\n",
    "model.summary()\n",
    "\n",
    "check  = ModelCheckpoint('best.hdf5', monitor = 'val_categorical_accuracy' )\n",
    "checkpoints = [check]\n",
    "\n",
    "model.fit(x_train, y_train, validation_split = 0.2, epochs=20, batch_size=32,verbose=2, callbacks = checkpoints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\envs\\workshop\\lib\\site-packages\\ipykernel_launcher.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (5, 5), input_shape=(32, 32, 3..., activation=\"relu\", padding=\"valid\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 106ms/step\n",
      "Pizza\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Flatten\n",
    "from keras.layers.convolutional import Convolution2D,MaxPooling2D\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "num_classes = 2\n",
    "\n",
    "img = cv2.imread('testObject2.jpg')\n",
    "imgRes = cv2.resize(img,(32,32))\n",
    "\n",
    "X_temp = []\n",
    "X_temp.append(imgRes)\n",
    "X = np.asarray(X_temp)\n",
    "X = X/255\n",
    "\n",
    "def CNN_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, 5, 5, border_mode= 'valid' , input_shape=(32,32,3),activation= 'relu' ))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation= 'relu' ))\n",
    "    model.add(Dense(num_classes, activation= 'softmax' ))\n",
    "    # Compile model\n",
    "    model.compile(loss= 'categorical_crossentropy' , optimizer= 'adam' , metrics=[ 'accuracy' ])\n",
    "    return model\n",
    "\n",
    "model = CNN_model()\n",
    "\n",
    "model.load_weights('best.hdf5')\n",
    "\n",
    "y = model.predict_classes(X)\n",
    "classno = np.ndarray.tolist(y)\n",
    "\n",
    "dict = {0: 'Burger', 1: 'Pizza'}\n",
    "objectClass = dict[classno[0]]\n",
    "print(objectClass)\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "cv2.putText(img, objectClass,(50,50), font, 2, (200,255,0), 5, cv2.LINE_AA)\n",
    "cv2.imshow('Prediction',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2.1\n",
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQ8jtel8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f3f1f6ccf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.002  1.002]\n",
      "[ 1.003991  1.003991]\n",
      "[ 1.00597304  1.00597304]\n",
      "[ 1.00794616  1.00794616]\n",
      "[ 1.0099104  1.0099104]\n",
      "[ 1.01186581  1.01186581]\n",
      "[ 1.01381241  1.01381241]\n",
      "[ 1.01575026  1.01575026]\n",
      "[ 1.01767938  1.01767938]\n",
      "[ 1.01959982  1.01959982]\n",
      "[ 1.02151162  1.02151162]\n",
      "[ 1.02341482  1.02341482]\n",
      "[ 1.02530945  1.02530945]\n",
      "[ 1.02719556  1.02719556]\n",
      "[ 1.02907318  1.02907318]\n",
      "[ 1.03094235  1.03094235]\n",
      "[ 1.03280311  1.03280311]\n",
      "[ 1.0346555  1.0346555]\n",
      "[ 1.03649955  1.03649955]\n",
      "[ 1.0383353  1.0383353]\n",
      "[ 1.04016279  1.04016279]\n",
      "[ 1.04198206  1.04198206]\n",
      "[ 1.04379314  1.04379314]\n",
      "[ 1.04559607  1.04559607]\n",
      "[ 1.04739089  1.04739089]\n",
      "[ 1.04917763  1.04917763]\n",
      "[ 1.05095633  1.05095633]\n",
      "[ 1.05272703  1.05272703]\n",
      "[ 1.05448975  1.05448975]\n",
      "[ 1.05624455  1.05624455]\n",
      "[ 1.05799145  1.05799145]\n",
      "[ 1.05973049  1.05973049]\n",
      "[ 1.0614617  1.0614617]\n",
      "[ 1.06318512  1.06318512]\n",
      "[ 1.06490079  1.06490079]\n",
      "[ 1.06660874  1.06660874]\n",
      "[ 1.068309  1.068309]\n",
      "[ 1.07000161  1.07000161]\n",
      "[ 1.0716866  1.0716866]\n",
      "[ 1.07336401  1.07336401]\n",
      "[ 1.07503387  1.07503387]\n",
      "[ 1.07669622  1.07669622]\n",
      "[ 1.07835109  1.07835109]\n",
      "[ 1.07999851  1.07999851]\n",
      "[ 1.08163851  1.08163851]\n",
      "[ 1.08327114  1.08327114]\n",
      "[ 1.08489642  1.08489642]\n",
      "[ 1.08651439  1.08651439]\n",
      "[ 1.08812507  1.08812507]\n",
      "[ 1.08972851  1.08972851]\n",
      "[ 1.09132473  1.09132473]\n",
      "[ 1.09291377  1.09291377]\n",
      "[ 1.09449566  1.09449566]\n",
      "[ 1.09607043  1.09607043]\n",
      "[ 1.09763811  1.09763811]\n",
      "[ 1.09919874  1.09919874]\n",
      "[ 1.10075234  1.10075234]\n",
      "[ 1.10229896  1.10229896]\n",
      "[ 1.10383861  1.10383861]\n",
      "[ 1.10537134  1.10537134]\n",
      "[ 1.10689717  1.10689717]\n",
      "[ 1.10841613  1.10841613]\n",
      "[ 1.10992826  1.10992826]\n",
      "[ 1.11143358  1.11143358]\n",
      "[ 1.11293213  1.11293213]\n",
      "[ 1.11442394  1.11442394]\n",
      "[ 1.11590903  1.11590903]\n",
      "[ 1.11738744  1.11738744]\n",
      "[ 1.11885919  1.11885919]\n",
      "[ 1.12032433  1.12032433]\n",
      "[ 1.12178287  1.12178287]\n",
      "[ 1.12323484  1.12323484]\n",
      "[ 1.12468029  1.12468029]\n",
      "[ 1.12611923  1.12611923]\n",
      "[ 1.12755169  1.12755169]\n",
      "[ 1.12897771  1.12897771]\n",
      "[ 1.13039731  1.13039731]\n",
      "[ 1.13181052  1.13181052]\n",
      "[ 1.13321737  1.13321737]\n",
      "[ 1.13461789  1.13461789]\n",
      "[ 1.13601211  1.13601211]\n",
      "[ 1.13740006  1.13740006]\n",
      "[ 1.13878176  1.13878176]\n",
      "[ 1.14015724  1.14015724]\n",
      "[ 1.14152653  1.14152653]\n",
      "[ 1.14288966  1.14288966]\n",
      "[ 1.14424666  1.14424666]\n",
      "[ 1.14559755  1.14559755]\n",
      "[ 1.14694236  1.14694236]\n",
      "[ 1.14828112  1.14828112]\n",
      "[ 1.14961386  1.14961386]\n",
      "[ 1.15094059  1.15094059]\n",
      "[ 1.15226136  1.15226136]\n",
      "[ 1.15357619  1.15357619]\n",
      "[ 1.15488509  1.15488509]\n",
      "[ 1.15618811  1.15618811]\n",
      "[ 1.15748526  1.15748526]\n",
      "[ 1.15877658  1.15877658]\n",
      "[ 1.16006208  1.16006208]\n",
      "[ 1.16134181  1.16134181]\n",
      "The computed value of Theta: [ 1.16134181  1.16134181]\n",
      "3.48402541539\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def gradientDescent(x, y, theta, alpha, m, numIterations):\n",
    "    xTrans = x.transpose()\n",
    "    for i in range(0, numIterations):\n",
    "        hypothesis = np.dot(x, theta)\n",
    "        loss = hypothesis - y \n",
    "        cost = np.sum(loss ** 2) / (2 * m)\n",
    "        #print(\"Iteration %d | Cost: %f\" % (i, cost))\n",
    "        # avg gradient per example\n",
    "        gradient = np.dot(xTrans, loss) / m \n",
    "        # update\n",
    "        theta = theta - alpha * gradient\n",
    "        print(theta)\n",
    "    return theta\n",
    "\n",
    "x = np.array([1,2])\n",
    "y= np.array([3,5])\n",
    "y=y.transpose()\n",
    "\n",
    "plt.plot(x,y,\"r\") \n",
    "plt.show()\n",
    "\n",
    "theta=([1,1])\n",
    "theta_grad= gradientDescent(x,y,theta,alpha=0.001,m=2,numIterations=100)\n",
    "\n",
    "print(\"The computed value of Theta:\",theta_grad)\n",
    "\n",
    "checker= np.array([1,2])\n",
    "basisVector = np.dot(theta_grad, checker.transpose())\n",
    "print(basisVector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.003  0.995]\n",
      " [ 1.004  0.992]]\n",
      "[[ 0.999957  0.992081]\n",
      " [ 0.999939  0.988115]]\n",
      "[[ 0.99695764  0.98920379]\n",
      " [ 0.99593991  0.98428928]]\n",
      "[[ 0.99400127  0.98636775]\n",
      " [ 0.99200181  0.98052196]]\n",
      "[[ 0.99108726  0.98357225]\n",
      " [ 0.98812378  0.97681217]]\n",
      "[[ 0.98821495  0.98081671]\n",
      " [ 0.98430493  0.97315904]]\n",
      "[[ 0.98538374  0.97810051]\n",
      " [ 0.98054438  0.96956173]]\n",
      "[[ 0.98259301  0.97542308]\n",
      " [ 0.97684125  0.96601941]]\n",
      "[[ 0.97984216  0.97278382]\n",
      " [ 0.97319469  0.96253126]]\n",
      "[[ 0.97713059  0.97018219]\n",
      " [ 0.96960384  0.95909646]]\n",
      "[[ 0.97445771  0.9676176 ]\n",
      " [ 0.96606789  0.95571422]]\n",
      "[[ 0.97182294  0.96508951]\n",
      " [ 0.96258601  0.95238375]]\n",
      "[[ 0.96922573  0.96259738]\n",
      " [ 0.95915739  0.94910429]]\n",
      "[[ 0.9666655   0.96014066]\n",
      " [ 0.95578123  0.94587507]]\n",
      "[[ 0.9641417   0.95771883]\n",
      " [ 0.95245676  0.94269533]]\n",
      "[[ 0.96165379  0.95533137]\n",
      " [ 0.9491832   0.93956434]]\n",
      "[[ 0.95920124  0.95297776]\n",
      " [ 0.94595979  0.93648138]]\n",
      "[[ 0.95678352  0.95065751]\n",
      " [ 0.94278579  0.93344572]]\n",
      "[[ 0.9544001   0.9483701 ]\n",
      " [ 0.93966045  0.93045666]]\n",
      "[[ 0.95205048  0.94611505]\n",
      " [ 0.93658304  0.92751351]]\n",
      "[[ 0.94973414  0.94389188]\n",
      " [ 0.93355286  0.92461557]]\n",
      "[[ 0.9474506   0.94170011]\n",
      " [ 0.93056919  0.92176217]]\n",
      "[[ 0.94519936  0.93953928]\n",
      " [ 0.92763134  0.91895264]]\n",
      "[[ 0.94297995  0.93740891]\n",
      " [ 0.92473863  0.91618634]]\n",
      "[[ 0.94079188  0.93530856]\n",
      " [ 0.92189039  0.91346262]]\n",
      "[[ 0.93863469  0.93323778]\n",
      " [ 0.91908594  0.91078083]]\n",
      "[[ 0.93650791  0.93119613]\n",
      " [ 0.91632464  0.90814036]]\n",
      "[[ 0.9344111   0.92918316]\n",
      " [ 0.91360584  0.90554058]]\n",
      "[[ 0.9323438   0.92719846]\n",
      " [ 0.9109289   0.90298089]]\n",
      "[[ 0.93030558  0.92524161]\n",
      " [ 0.90829321  0.9004607 ]]\n",
      "[[ 0.928296    0.92331217]\n",
      " [ 0.90569813  0.8979794 ]]\n",
      "[[ 0.92631463  0.92140976]\n",
      " [ 0.90314308  0.89553642]]\n",
      "[[ 0.92436106  0.91953395]\n",
      " [ 0.90062745  0.89313119]]\n",
      "[[ 0.92243486  0.91768436]\n",
      " [ 0.89815065  0.89076314]]\n",
      "[[ 0.92053563  0.9158606 ]\n",
      " [ 0.89571209  0.88843171]]\n",
      "[[ 0.91866297  0.91406228]\n",
      " [ 0.89331122  0.88613637]]\n",
      "[[ 0.91681648  0.91228901]\n",
      " [ 0.89094747  0.88387657]]\n",
      "[[ 0.91499576  0.91054043]\n",
      " [ 0.88862028  0.88165178]]\n",
      "[[ 0.91320044  0.90881616]\n",
      " [ 0.88632911  0.87946148]]\n",
      "[[ 0.91143014  0.90711585]\n",
      " [ 0.88407341  0.87730516]]\n",
      "[[ 0.90968447  0.90543914]\n",
      " [ 0.88185267  0.87518229]]\n",
      "[[ 0.90796308  0.90378567]\n",
      " [ 0.87966635  0.8730924 ]]\n",
      "[[ 0.9062656   0.90215509]\n",
      " [ 0.87751395  0.87103497]]\n",
      "[[ 0.90459167  0.90054707]\n",
      " [ 0.87539495  0.86900954]]\n",
      "[[ 0.90294095  0.89896127]\n",
      " [ 0.87330886  0.86701561]]\n",
      "[[ 0.90131308  0.89739735]\n",
      " [ 0.87125518  0.86505273]]\n",
      "[[ 0.89970773  0.895855  ]\n",
      " [ 0.86923344  0.86312042]]\n",
      "[[ 0.89812456  0.89433388]\n",
      " [ 0.86724315  0.86121823]]\n",
      "[[ 0.89656324  0.89283368]\n",
      " [ 0.86528385  0.85934571]]\n",
      "[[ 0.89502343  0.89135409]\n",
      " [ 0.86335506  0.85750242]]\n",
      "[[ 0.89350483  0.88989481]\n",
      " [ 0.86145635  0.85568791]]\n",
      "[[ 0.89200711  0.88845552]\n",
      " [ 0.85958725  0.85390177]]\n",
      "[[ 0.89052996  0.88703593]\n",
      " [ 0.85774733  0.85214357]]\n",
      "[[ 0.88907308  0.88563574]\n",
      " [ 0.85593615  0.85041288]]\n",
      "[[ 0.88763616  0.88425467]\n",
      " [ 0.85415327  0.8487093 ]]\n",
      "[[ 0.88621891  0.88289243]\n",
      " [ 0.85239829  0.84703242]]\n",
      "[[ 0.88482103  0.88154875]\n",
      " [ 0.85067077  0.84538185]]\n",
      "[[ 0.88344223  0.88022333]\n",
      " [ 0.84897032  0.84375719]]\n",
      "[[ 0.88208222  0.87891591]\n",
      " [ 0.84729652  0.84215806]]\n",
      "[[ 0.88074074  0.87762623]\n",
      " [ 0.84564898  0.84058407]]\n",
      "[[ 0.87941749  0.87635401]\n",
      " [ 0.8440273   0.83903484]]\n",
      "[[ 0.87811221  0.87509899]\n",
      " [ 0.84243111  0.83751001]]\n",
      "[[ 0.87682463  0.87386093]\n",
      " [ 0.84086001  0.83600922]]\n",
      "[[ 0.87555449  0.87263956]\n",
      " [ 0.83931364  0.8345321 ]]\n",
      "[[ 0.87430152  0.87143464]\n",
      " [ 0.83779162  0.8330783 ]]\n",
      "[[ 0.87306547  0.87024591]\n",
      " [ 0.83629359  0.83164748]]\n",
      "[[ 0.87184609  0.86907315]\n",
      " [ 0.8348192   0.83023928]]\n",
      "[[ 0.87064313  0.86791611]\n",
      " [ 0.83336809  0.82885338]]\n",
      "[[ 0.86945633  0.86677456]\n",
      " [ 0.8319399   0.82748943]]\n",
      "[[ 0.86828547  0.86564826]\n",
      " [ 0.83053431  0.82614712]]\n",
      "[[ 0.86713031  0.86453699]\n",
      " [ 0.82915097  0.82482611]]\n",
      "[[ 0.8659906   0.86344052]\n",
      " [ 0.82778955  0.82352609]]\n",
      "[[ 0.86486612  0.86235863]\n",
      " [ 0.82644972  0.82224674]]\n",
      "[[ 0.86375664  0.86129111]\n",
      " [ 0.82513116  0.82098776]]\n",
      "[[ 0.86266194  0.86023774]\n",
      " [ 0.82383355  0.81974885]]\n",
      "[[ 0.86158179  0.85919831]\n",
      " [ 0.82255658  0.8185297 ]]\n",
      "[[ 0.86051599  0.85817261]\n",
      " [ 0.82129994  0.81733001]]\n",
      "[[ 0.85946431  0.85716044]\n",
      " [ 0.82006333  0.8161495 ]]\n",
      "[[ 0.85842654  0.85616159]\n",
      " [ 0.81884645  0.81498788]]\n",
      "[[ 0.85740249  0.85517587]\n",
      " [ 0.817649    0.81384487]]\n",
      "[[ 0.85639193  0.85420308]\n",
      " [ 0.81647069  0.81272019]]\n",
      "[[ 0.85539468  0.85324302]\n",
      " [ 0.81531124  0.81161357]]\n",
      "[[ 0.85441052  0.85229551]\n",
      " [ 0.81417036  0.81052473]]\n",
      "[[ 0.85343928  0.85136036]\n",
      " [ 0.81304779  0.80945342]]\n",
      "[[ 0.85248075  0.85043738]\n",
      " [ 0.81194323  0.80839936]]\n",
      "[[ 0.85153474  0.8495264 ]\n",
      " [ 0.81085644  0.80736231]]\n",
      "[[ 0.85060107  0.84862723]\n",
      " [ 0.80978713  0.806342  ]]\n",
      "[[ 0.84967956  0.8477397 ]\n",
      " [ 0.80873505  0.80533819]]\n",
      "[[ 0.84877001  0.84686364]\n",
      " [ 0.80769994  0.80435063]]\n",
      "[[ 0.84787226  0.84599886]\n",
      " [ 0.80668155  0.80337908]]\n",
      "[[ 0.84698613  0.84514522]\n",
      " [ 0.80567963  0.80242329]]\n",
      "[[ 0.84611144  0.84430253]\n",
      " [ 0.80469393  0.80148304]]\n",
      "[[ 0.84524803  0.84347063]\n",
      " [ 0.80372421  0.8005581 ]]\n",
      "[[ 0.84439572  0.84264937]\n",
      " [ 0.80277023  0.79964822]]\n",
      "[[ 0.84355435  0.84183859]\n",
      " [ 0.80183176  0.79875319]]\n",
      "[[ 0.84272376  0.84103812]\n",
      " [ 0.80090856  0.79787279]]\n",
      "[[ 0.84190378  0.84024782]\n",
      " [ 0.80000041  0.7970068 ]]\n",
      "[[ 0.84109426  0.83946754]\n",
      " [ 0.79910708  0.79615499]]\n",
      "[[ 0.84029503  0.83869711]\n",
      " [ 0.79822835  0.79531717]]\n",
      "[[ 0.83950596  0.83793641]\n",
      " [ 0.797364    0.79449312]]\n",
      "The computed value of Theta: [[ 0.83950596  0.83793641]\n",
      " [ 0.797364    0.79449312]]\n",
      "[[ 2.51537878  2.38635024]]\n"
     ]
    }
   ],
   "source": [
    "x = np.matrix([[1,2], [3, 4]])\n",
    "y= np.matrix([3, 5])\n",
    "y=y.transpose()\n",
    "plt.plot(x,y,\"r\") \n",
    "#plt.show()\n",
    "\n",
    "theta=([1,1])\n",
    "theta_grad= gradientDescent(x,y,theta,alpha=0.001,m=2,numIterations=100)\n",
    "\n",
    "print(\"The computed value of Theta:\",theta_grad)\n",
    "\n",
    "checker= np.array([1,2])\n",
    "basisVector = np.dot(theta_grad, checker.transpose())\n",
    "print(basisVector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more details: http://scikit-learn.org/stable/modules/sgd.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2.2\n",
    "# Section 2.2.1\n",
    "# Single Variable Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Necessary Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the diabetes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diabetes = datasets.load_diabetes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets Take a look at the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[ 0.03807591,  0.05068012,  0.06169621, ..., -0.00259226,\n",
      "         0.01990842, -0.01764613],\n",
      "       [-0.00188202, -0.04464164, -0.05147406, ..., -0.03949338,\n",
      "        -0.06832974, -0.09220405],\n",
      "       [ 0.08529891,  0.05068012,  0.04445121, ..., -0.00259226,\n",
      "         0.00286377, -0.02593034],\n",
      "       ..., \n",
      "       [ 0.04170844,  0.05068012, -0.01590626, ..., -0.01107952,\n",
      "        -0.04687948,  0.01549073],\n",
      "       [-0.04547248, -0.04464164,  0.03906215, ...,  0.02655962,\n",
      "         0.04452837, -0.02593034],\n",
      "       [-0.04547248, -0.04464164, -0.0730303 , ..., -0.03949338,\n",
      "        -0.00421986,  0.00306441]]), 'target': array([ 151.,   75.,  141.,  206.,  135.,   97.,  138.,   63.,  110.,\n",
      "        310.,  101.,   69.,  179.,  185.,  118.,  171.,  166.,  144.,\n",
      "         97.,  168.,   68.,   49.,   68.,  245.,  184.,  202.,  137.,\n",
      "         85.,  131.,  283.,  129.,   59.,  341.,   87.,   65.,  102.,\n",
      "        265.,  276.,  252.,   90.,  100.,   55.,   61.,   92.,  259.,\n",
      "         53.,  190.,  142.,   75.,  142.,  155.,  225.,   59.,  104.,\n",
      "        182.,  128.,   52.,   37.,  170.,  170.,   61.,  144.,   52.,\n",
      "        128.,   71.,  163.,  150.,   97.,  160.,  178.,   48.,  270.,\n",
      "        202.,  111.,   85.,   42.,  170.,  200.,  252.,  113.,  143.,\n",
      "         51.,   52.,  210.,   65.,  141.,   55.,  134.,   42.,  111.,\n",
      "         98.,  164.,   48.,   96.,   90.,  162.,  150.,  279.,   92.,\n",
      "         83.,  128.,  102.,  302.,  198.,   95.,   53.,  134.,  144.,\n",
      "        232.,   81.,  104.,   59.,  246.,  297.,  258.,  229.,  275.,\n",
      "        281.,  179.,  200.,  200.,  173.,  180.,   84.,  121.,  161.,\n",
      "         99.,  109.,  115.,  268.,  274.,  158.,  107.,   83.,  103.,\n",
      "        272.,   85.,  280.,  336.,  281.,  118.,  317.,  235.,   60.,\n",
      "        174.,  259.,  178.,  128.,   96.,  126.,  288.,   88.,  292.,\n",
      "         71.,  197.,  186.,   25.,   84.,   96.,  195.,   53.,  217.,\n",
      "        172.,  131.,  214.,   59.,   70.,  220.,  268.,  152.,   47.,\n",
      "         74.,  295.,  101.,  151.,  127.,  237.,  225.,   81.,  151.,\n",
      "        107.,   64.,  138.,  185.,  265.,  101.,  137.,  143.,  141.,\n",
      "         79.,  292.,  178.,   91.,  116.,   86.,  122.,   72.,  129.,\n",
      "        142.,   90.,  158.,   39.,  196.,  222.,  277.,   99.,  196.,\n",
      "        202.,  155.,   77.,  191.,   70.,   73.,   49.,   65.,  263.,\n",
      "        248.,  296.,  214.,  185.,   78.,   93.,  252.,  150.,   77.,\n",
      "        208.,   77.,  108.,  160.,   53.,  220.,  154.,  259.,   90.,\n",
      "        246.,  124.,   67.,   72.,  257.,  262.,  275.,  177.,   71.,\n",
      "         47.,  187.,  125.,   78.,   51.,  258.,  215.,  303.,  243.,\n",
      "         91.,  150.,  310.,  153.,  346.,   63.,   89.,   50.,   39.,\n",
      "        103.,  308.,  116.,  145.,   74.,   45.,  115.,  264.,   87.,\n",
      "        202.,  127.,  182.,  241.,   66.,   94.,  283.,   64.,  102.,\n",
      "        200.,  265.,   94.,  230.,  181.,  156.,  233.,   60.,  219.,\n",
      "         80.,   68.,  332.,  248.,   84.,  200.,   55.,   85.,   89.,\n",
      "         31.,  129.,   83.,  275.,   65.,  198.,  236.,  253.,  124.,\n",
      "         44.,  172.,  114.,  142.,  109.,  180.,  144.,  163.,  147.,\n",
      "         97.,  220.,  190.,  109.,  191.,  122.,  230.,  242.,  248.,\n",
      "        249.,  192.,  131.,  237.,   78.,  135.,  244.,  199.,  270.,\n",
      "        164.,   72.,   96.,  306.,   91.,  214.,   95.,  216.,  263.,\n",
      "        178.,  113.,  200.,  139.,  139.,   88.,  148.,   88.,  243.,\n",
      "         71.,   77.,  109.,  272.,   60.,   54.,  221.,   90.,  311.,\n",
      "        281.,  182.,  321.,   58.,  262.,  206.,  233.,  242.,  123.,\n",
      "        167.,   63.,  197.,   71.,  168.,  140.,  217.,  121.,  235.,\n",
      "        245.,   40.,   52.,  104.,  132.,   88.,   69.,  219.,   72.,\n",
      "        201.,  110.,   51.,  277.,   63.,  118.,   69.,  273.,  258.,\n",
      "         43.,  198.,  242.,  232.,  175.,   93.,  168.,  275.,  293.,\n",
      "        281.,   72.,  140.,  189.,  181.,  209.,  136.,  261.,  113.,\n",
      "        131.,  174.,  257.,   55.,   84.,   42.,  146.,  212.,  233.,\n",
      "         91.,  111.,  152.,  120.,   67.,  310.,   94.,  183.,   66.,\n",
      "        173.,   72.,   49.,   64.,   48.,  178.,  104.,  132.,  220.,   57.]), 'DESCR': 'Diabetes dataset\\n================\\n\\nNotes\\n-----\\n\\nTen baseline variables, age, sex, body mass index, average blood\\npressure, and six blood serum measurements were obtained for each of n =\\n442 diabetes patients, as well as the response of interest, a\\nquantitative measure of disease progression one year after baseline.\\n\\nData Set Characteristics:\\n\\n  :Number of Instances: 442\\n\\n  :Number of Attributes: First 10 columns are numeric predictive values\\n\\n  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\\n\\n  :Attributes:\\n    :Age:\\n    :Sex:\\n    :Body mass index:\\n    :Average blood pressure:\\n    :S1:\\n    :S2:\\n    :S3:\\n    :S4:\\n    :S5:\\n    :S6:\\n\\nNote: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\\n\\nSource URL:\\nhttp://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\\n\\nFor more information see:\\nBradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\\n(http://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\\n', 'feature_names': ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']}\n",
      "<class 'sklearn.utils.Bunch'>\n"
     ]
    }
   ],
   "source": [
    "print(diabetes)\n",
    "print(type(diabetes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use only one feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diabetes_X = diabetes.data[:, np.newaxis, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into training/testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.06169621]\n",
      " [-0.05147406]\n",
      " [ 0.04445121]\n",
      " [-0.01159501]\n",
      " [-0.03638469]\n",
      " [-0.04069594]\n",
      " [-0.04716281]\n",
      " [-0.00189471]\n",
      " [ 0.06169621]\n",
      " [ 0.03906215]\n",
      " [-0.08380842]\n",
      " [ 0.01750591]\n",
      " [-0.02884001]\n",
      " [-0.00189471]\n",
      " [-0.02560657]\n",
      " [-0.01806189]\n",
      " [ 0.04229559]\n",
      " [ 0.01211685]\n",
      " [-0.0105172 ]\n",
      " [-0.01806189]\n",
      " [-0.05686312]\n",
      " [-0.02237314]\n",
      " [-0.00405033]\n",
      " [ 0.06061839]\n",
      " [ 0.03582872]\n",
      " [-0.01267283]\n",
      " [-0.07734155]\n",
      " [ 0.05954058]\n",
      " [-0.02129532]\n",
      " [-0.00620595]\n",
      " [ 0.04445121]\n",
      " [-0.06548562]\n",
      " [ 0.12528712]\n",
      " [-0.05039625]\n",
      " [-0.06332999]\n",
      " [-0.03099563]\n",
      " [ 0.02289497]\n",
      " [ 0.01103904]\n",
      " [ 0.07139652]\n",
      " [ 0.01427248]\n",
      " [-0.00836158]\n",
      " [-0.06764124]\n",
      " [-0.0105172 ]\n",
      " [-0.02345095]\n",
      " [ 0.06816308]\n",
      " [-0.03530688]\n",
      " [-0.01159501]\n",
      " [-0.0730303 ]\n",
      " [-0.04177375]\n",
      " [ 0.01427248]\n",
      " [-0.00728377]\n",
      " [ 0.0164281 ]\n",
      " [-0.00943939]\n",
      " [-0.01590626]\n",
      " [ 0.0250506 ]\n",
      " [-0.04931844]\n",
      " [ 0.04121778]\n",
      " [-0.06332999]\n",
      " [-0.06440781]\n",
      " [-0.02560657]\n",
      " [-0.00405033]\n",
      " [ 0.00457217]\n",
      " [-0.00728377]\n",
      " [-0.0374625 ]\n",
      " [-0.02560657]\n",
      " [-0.02452876]\n",
      " [-0.01806189]\n",
      " [-0.01482845]\n",
      " [-0.02991782]\n",
      " [-0.046085  ]\n",
      " [-0.06979687]\n",
      " [ 0.03367309]\n",
      " [-0.00405033]\n",
      " [-0.02021751]\n",
      " [ 0.00241654]\n",
      " [-0.03099563]\n",
      " [ 0.02828403]\n",
      " [-0.03638469]\n",
      " [-0.05794093]\n",
      " [-0.0374625 ]\n",
      " [ 0.01211685]\n",
      " [-0.02237314]\n",
      " [-0.03530688]\n",
      " [ 0.00996123]\n",
      " [-0.03961813]\n",
      " [ 0.07139652]\n",
      " [-0.07518593]\n",
      " [-0.00620595]\n",
      " [-0.04069594]\n",
      " [-0.04824063]\n",
      " [-0.02560657]\n",
      " [ 0.0519959 ]\n",
      " [ 0.00457217]\n",
      " [-0.06440781]\n",
      " [-0.01698407]\n",
      " [-0.05794093]\n",
      " [ 0.00996123]\n",
      " [ 0.08864151]\n",
      " [-0.00512814]\n",
      " [-0.06440781]\n",
      " [ 0.01750591]\n",
      " [-0.04500719]\n",
      " [ 0.02828403]\n",
      " [ 0.04121778]\n",
      " [ 0.06492964]\n",
      " [-0.03207344]\n",
      " [-0.07626374]\n",
      " [ 0.04984027]\n",
      " [ 0.04552903]\n",
      " [-0.00943939]\n",
      " [-0.03207344]\n",
      " [ 0.00457217]\n",
      " [ 0.02073935]\n",
      " [ 0.01427248]\n",
      " [ 0.11019775]\n",
      " [ 0.00133873]\n",
      " [ 0.05846277]\n",
      " [-0.02129532]\n",
      " [-0.0105172 ]\n",
      " [-0.04716281]\n",
      " [ 0.00457217]\n",
      " [ 0.01750591]\n",
      " [ 0.08109682]\n",
      " [ 0.0347509 ]\n",
      " [ 0.02397278]\n",
      " [-0.00836158]\n",
      " [-0.06117437]\n",
      " [-0.00189471]\n",
      " [-0.06225218]\n",
      " [ 0.0164281 ]\n",
      " [ 0.09618619]\n",
      " [-0.06979687]\n",
      " [-0.02129532]\n",
      " [-0.05362969]\n",
      " [ 0.0433734 ]\n",
      " [ 0.05630715]\n",
      " [-0.0816528 ]\n",
      " [ 0.04984027]\n",
      " [ 0.11127556]\n",
      " [ 0.06169621]\n",
      " [ 0.01427248]\n",
      " [ 0.04768465]\n",
      " [ 0.01211685]\n",
      " [ 0.00564998]\n",
      " [ 0.04660684]\n",
      " [ 0.12852056]\n",
      " [ 0.05954058]\n",
      " [ 0.09295276]\n",
      " [ 0.01535029]\n",
      " [-0.00512814]\n",
      " [ 0.0703187 ]\n",
      " [-0.00405033]\n",
      " [-0.00081689]\n",
      " [-0.04392938]\n",
      " [ 0.02073935]\n",
      " [ 0.06061839]\n",
      " [-0.0105172 ]\n",
      " [-0.03315126]\n",
      " [-0.06548562]\n",
      " [ 0.0433734 ]\n",
      " [-0.06225218]\n",
      " [ 0.06385183]\n",
      " [ 0.03043966]\n",
      " [ 0.07247433]\n",
      " [-0.0191397 ]\n",
      " [-0.06656343]\n",
      " [-0.06009656]\n",
      " [ 0.06924089]\n",
      " [ 0.05954058]\n",
      " [-0.02668438]\n",
      " [-0.02021751]\n",
      " [-0.046085  ]\n",
      " [ 0.07139652]\n",
      " [-0.07949718]\n",
      " [ 0.00996123]\n",
      " [-0.03854032]\n",
      " [ 0.01966154]\n",
      " [ 0.02720622]\n",
      " [-0.00836158]\n",
      " [-0.01590626]\n",
      " [ 0.00457217]\n",
      " [-0.04285156]\n",
      " [ 0.00564998]\n",
      " [-0.03530688]\n",
      " [ 0.02397278]\n",
      " [-0.01806189]\n",
      " [ 0.04229559]\n",
      " [-0.0547075 ]\n",
      " [-0.00297252]\n",
      " [-0.06656343]\n",
      " [-0.01267283]\n",
      " [-0.04177375]\n",
      " [-0.03099563]\n",
      " [-0.00512814]\n",
      " [-0.05901875]\n",
      " [ 0.0250506 ]\n",
      " [-0.046085  ]\n",
      " [ 0.00349435]\n",
      " [ 0.05415152]\n",
      " [-0.04500719]\n",
      " [-0.05794093]\n",
      " [-0.05578531]\n",
      " [ 0.00133873]\n",
      " [ 0.03043966]\n",
      " [ 0.00672779]\n",
      " [ 0.04660684]\n",
      " [ 0.02612841]\n",
      " [ 0.04552903]\n",
      " [ 0.04013997]\n",
      " [-0.01806189]\n",
      " [ 0.01427248]\n",
      " [ 0.03690653]\n",
      " [ 0.00349435]\n",
      " [-0.07087468]\n",
      " [-0.03315126]\n",
      " [ 0.09403057]\n",
      " [ 0.03582872]\n",
      " [ 0.03151747]\n",
      " [-0.06548562]\n",
      " [-0.04177375]\n",
      " [-0.03961813]\n",
      " [-0.03854032]\n",
      " [-0.02560657]\n",
      " [-0.02345095]\n",
      " [-0.06656343]\n",
      " [ 0.03259528]\n",
      " [-0.046085  ]\n",
      " [-0.02991782]\n",
      " [-0.01267283]\n",
      " [-0.01590626]\n",
      " [ 0.07139652]\n",
      " [-0.03099563]\n",
      " [ 0.00026092]\n",
      " [ 0.03690653]\n",
      " [ 0.03906215]\n",
      " [-0.01482845]\n",
      " [ 0.00672779]\n",
      " [-0.06871905]\n",
      " [-0.00943939]\n",
      " [ 0.01966154]\n",
      " [ 0.07462995]\n",
      " [-0.00836158]\n",
      " [-0.02345095]\n",
      " [-0.046085  ]\n",
      " [ 0.05415152]\n",
      " [-0.03530688]\n",
      " [-0.03207344]\n",
      " [-0.0816528 ]\n",
      " [ 0.04768465]\n",
      " [ 0.06061839]\n",
      " [ 0.05630715]\n",
      " [ 0.09834182]\n",
      " [ 0.05954058]\n",
      " [ 0.03367309]\n",
      " [ 0.05630715]\n",
      " [-0.06548562]\n",
      " [ 0.16085492]\n",
      " [-0.05578531]\n",
      " [-0.02452876]\n",
      " [-0.03638469]\n",
      " [-0.00836158]\n",
      " [-0.04177375]\n",
      " [ 0.12744274]\n",
      " [-0.07734155]\n",
      " [ 0.02828403]\n",
      " [-0.02560657]\n",
      " [-0.06225218]\n",
      " [-0.00081689]\n",
      " [ 0.08864151]\n",
      " [-0.03207344]\n",
      " [ 0.03043966]\n",
      " [ 0.00888341]\n",
      " [ 0.00672779]\n",
      " [-0.02021751]\n",
      " [-0.02452876]\n",
      " [-0.01159501]\n",
      " [ 0.02612841]\n",
      " [-0.05901875]\n",
      " [-0.03638469]\n",
      " [-0.02452876]\n",
      " [ 0.01858372]\n",
      " [-0.0902753 ]\n",
      " [-0.00512814]\n",
      " [-0.05255187]\n",
      " [-0.02237314]\n",
      " [-0.02021751]\n",
      " [-0.0547075 ]\n",
      " [-0.00620595]\n",
      " [-0.01698407]\n",
      " [ 0.05522933]\n",
      " [ 0.07678558]\n",
      " [ 0.01858372]\n",
      " [-0.02237314]\n",
      " [ 0.09295276]\n",
      " [-0.03099563]\n",
      " [ 0.03906215]\n",
      " [-0.06117437]\n",
      " [-0.00836158]\n",
      " [-0.0374625 ]\n",
      " [-0.01375064]\n",
      " [ 0.07355214]\n",
      " [-0.02452876]\n",
      " [ 0.03367309]\n",
      " [ 0.0347509 ]\n",
      " [-0.03854032]\n",
      " [-0.03961813]\n",
      " [-0.00189471]\n",
      " [-0.03099563]\n",
      " [-0.046085  ]\n",
      " [ 0.00133873]\n",
      " [ 0.06492964]\n",
      " [ 0.04013997]\n",
      " [-0.02345095]\n",
      " [ 0.05307371]\n",
      " [ 0.04013997]\n",
      " [-0.02021751]\n",
      " [ 0.01427248]\n",
      " [-0.03422907]\n",
      " [ 0.00672779]\n",
      " [ 0.00457217]\n",
      " [ 0.03043966]\n",
      " [ 0.0519959 ]\n",
      " [ 0.06169621]\n",
      " [-0.00728377]\n",
      " [ 0.00564998]\n",
      " [ 0.05415152]\n",
      " [-0.00836158]\n",
      " [ 0.114509  ]\n",
      " [ 0.06708527]\n",
      " [-0.05578531]\n",
      " [ 0.03043966]\n",
      " [-0.02560657]\n",
      " [ 0.10480869]\n",
      " [-0.00620595]\n",
      " [-0.04716281]\n",
      " [-0.04824063]\n",
      " [ 0.08540807]\n",
      " [-0.01267283]\n",
      " [-0.03315126]\n",
      " [-0.00728377]\n",
      " [-0.01375064]\n",
      " [ 0.05954058]\n",
      " [ 0.02181716]\n",
      " [ 0.01858372]\n",
      " [-0.01159501]\n",
      " [-0.00297252]\n",
      " [ 0.01750591]\n",
      " [-0.02991782]\n",
      " [-0.02021751]\n",
      " [-0.05794093]\n",
      " [ 0.06061839]\n",
      " [-0.04069594]\n",
      " [-0.07195249]\n",
      " [-0.05578531]\n",
      " [ 0.04552903]\n",
      " [-0.00943939]\n",
      " [-0.03315126]\n",
      " [ 0.04984027]\n",
      " [-0.08488624]\n",
      " [ 0.00564998]\n",
      " [ 0.02073935]\n",
      " [-0.00728377]\n",
      " [ 0.10480869]\n",
      " [-0.02452876]\n",
      " [-0.00620595]\n",
      " [-0.03854032]\n",
      " [ 0.13714305]\n",
      " [ 0.17055523]\n",
      " [ 0.00241654]\n",
      " [ 0.03798434]\n",
      " [-0.05794093]\n",
      " [-0.00943939]\n",
      " [-0.02345095]\n",
      " [-0.0105172 ]\n",
      " [-0.03422907]\n",
      " [-0.00297252]\n",
      " [ 0.06816308]\n",
      " [ 0.00996123]\n",
      " [ 0.00241654]\n",
      " [-0.03854032]\n",
      " [ 0.02612841]\n",
      " [-0.08919748]\n",
      " [ 0.06061839]\n",
      " [-0.02884001]\n",
      " [-0.02991782]\n",
      " [-0.0191397 ]\n",
      " [-0.04069594]\n",
      " [ 0.01535029]\n",
      " [-0.02452876]\n",
      " [ 0.00133873]\n",
      " [ 0.06924089]\n",
      " [-0.06979687]\n",
      " [-0.02991782]\n",
      " [-0.046085  ]\n",
      " [ 0.01858372]\n",
      " [ 0.00133873]\n",
      " [-0.03099563]\n",
      " [-0.00405033]\n",
      " [ 0.01535029]\n",
      " [ 0.02289497]\n",
      " [ 0.04552903]\n",
      " [-0.04500719]\n",
      " [-0.03315126]\n",
      " [ 0.097264  ]\n",
      " [ 0.05415152]\n",
      " [ 0.12313149]\n",
      " [-0.08057499]\n",
      " [ 0.09295276]\n",
      " [-0.05039625]\n",
      " [-0.01159501]\n",
      " [-0.0277622 ]\n",
      " [ 0.05846277]\n",
      " [ 0.08540807]\n",
      " [-0.00081689]\n",
      " [ 0.00672779]\n",
      " [ 0.00888341]\n",
      " [ 0.08001901]\n",
      " [ 0.07139652]\n",
      " [-0.02452876]\n",
      " [-0.0547075 ]\n",
      " [-0.03638469]\n",
      " [ 0.0164281 ]] [[ 0.07786339]\n",
      " [-0.03961813]\n",
      " [ 0.01103904]\n",
      " [-0.04069594]\n",
      " [-0.03422907]\n",
      " [ 0.00564998]\n",
      " [ 0.08864151]\n",
      " [-0.03315126]\n",
      " [-0.05686312]\n",
      " [-0.03099563]\n",
      " [ 0.05522933]\n",
      " [-0.06009656]\n",
      " [ 0.00133873]\n",
      " [-0.02345095]\n",
      " [-0.07410811]\n",
      " [ 0.01966154]\n",
      " [-0.01590626]\n",
      " [-0.01590626]\n",
      " [ 0.03906215]\n",
      " [-0.0730303 ]]\n"
     ]
    }
   ],
   "source": [
    "diabetes_X_train = diabetes_X[:-20]\n",
    "diabetes_X_test = diabetes_X[-20:]\n",
    "\n",
    "print(diabetes_X_train, diabetes_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the targets into training/testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 151.   75.  141.  206.  135.   97.  138.   63.  110.  310.  101.   69.\n",
      "  179.  185.  118.  171.  166.  144.   97.  168.   68.   49.   68.  245.\n",
      "  184.  202.  137.   85.  131.  283.  129.   59.  341.   87.   65.  102.\n",
      "  265.  276.  252.   90.  100.   55.   61.   92.  259.   53.  190.  142.\n",
      "   75.  142.  155.  225.   59.  104.  182.  128.   52.   37.  170.  170.\n",
      "   61.  144.   52.  128.   71.  163.  150.   97.  160.  178.   48.  270.\n",
      "  202.  111.   85.   42.  170.  200.  252.  113.  143.   51.   52.  210.\n",
      "   65.  141.   55.  134.   42.  111.   98.  164.   48.   96.   90.  162.\n",
      "  150.  279.   92.   83.  128.  102.  302.  198.   95.   53.  134.  144.\n",
      "  232.   81.  104.   59.  246.  297.  258.  229.  275.  281.  179.  200.\n",
      "  200.  173.  180.   84.  121.  161.   99.  109.  115.  268.  274.  158.\n",
      "  107.   83.  103.  272.   85.  280.  336.  281.  118.  317.  235.   60.\n",
      "  174.  259.  178.  128.   96.  126.  288.   88.  292.   71.  197.  186.\n",
      "   25.   84.   96.  195.   53.  217.  172.  131.  214.   59.   70.  220.\n",
      "  268.  152.   47.   74.  295.  101.  151.  127.  237.  225.   81.  151.\n",
      "  107.   64.  138.  185.  265.  101.  137.  143.  141.   79.  292.  178.\n",
      "   91.  116.   86.  122.   72.  129.  142.   90.  158.   39.  196.  222.\n",
      "  277.   99.  196.  202.  155.   77.  191.   70.   73.   49.   65.  263.\n",
      "  248.  296.  214.  185.   78.   93.  252.  150.   77.  208.   77.  108.\n",
      "  160.   53.  220.  154.  259.   90.  246.  124.   67.   72.  257.  262.\n",
      "  275.  177.   71.   47.  187.  125.   78.   51.  258.  215.  303.  243.\n",
      "   91.  150.  310.  153.  346.   63.   89.   50.   39.  103.  308.  116.\n",
      "  145.   74.   45.  115.  264.   87.  202.  127.  182.  241.   66.   94.\n",
      "  283.   64.  102.  200.  265.   94.  230.  181.  156.  233.   60.  219.\n",
      "   80.   68.  332.  248.   84.  200.   55.   85.   89.   31.  129.   83.\n",
      "  275.   65.  198.  236.  253.  124.   44.  172.  114.  142.  109.  180.\n",
      "  144.  163.  147.   97.  220.  190.  109.  191.  122.  230.  242.  248.\n",
      "  249.  192.  131.  237.   78.  135.  244.  199.  270.  164.   72.   96.\n",
      "  306.   91.  214.   95.  216.  263.  178.  113.  200.  139.  139.   88.\n",
      "  148.   88.  243.   71.   77.  109.  272.   60.   54.  221.   90.  311.\n",
      "  281.  182.  321.   58.  262.  206.  233.  242.  123.  167.   63.  197.\n",
      "   71.  168.  140.  217.  121.  235.  245.   40.   52.  104.  132.   88.\n",
      "   69.  219.   72.  201.  110.   51.  277.   63.  118.   69.  273.  258.\n",
      "   43.  198.  242.  232.  175.   93.  168.  275.  293.  281.   72.  140.\n",
      "  189.  181.  209.  136.  261.  113.  131.  174.  257.   55.   84.   42.\n",
      "  146.  212.]\n"
     ]
    }
   ],
   "source": [
    "diabetes_y_train = diabetes.target[:-20]\n",
    "diabetes_y_test = diabetes.target[-20:]\n",
    "\n",
    "print(diabetes_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create linear regression object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "regr = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model using the training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.fit(diabetes_X_train, diabetes_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions using the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.07786339]\n",
      " [-0.03961813]\n",
      " [ 0.01103904]\n",
      " [-0.04069594]\n",
      " [-0.03422907]\n",
      " [ 0.00564998]\n",
      " [ 0.08864151]\n",
      " [-0.03315126]\n",
      " [-0.05686312]\n",
      " [-0.03099563]\n",
      " [ 0.05522933]\n",
      " [-0.06009656]\n",
      " [ 0.00133873]\n",
      " [-0.02345095]\n",
      " [-0.07410811]\n",
      " [ 0.01966154]\n",
      " [-0.01590626]\n",
      " [-0.01590626]\n",
      " [ 0.03906215]\n",
      " [-0.0730303 ]]\n",
      "[ 225.9732401   115.74763374  163.27610621  114.73638965  120.80385422\n",
      "  158.21988574  236.08568105  121.81509832   99.56772822  123.83758651\n",
      "  204.73711411   96.53399594  154.17490936  130.91629517   83.3878227\n",
      "  171.36605897  137.99500384  137.99500384  189.56845268   84.3990668 ]\n",
      "[ 233.   91.  111.  152.  120.   67.  310.   94.  183.   66.  173.   72.\n",
      "   49.   64.   48.  178.  104.  132.  220.   57.]\n"
     ]
    }
   ],
   "source": [
    "diabetes_y_pred = regr.predict(diabetes_X_test)\n",
    "print(diabetes_X_test)\n",
    "print(diabetes_y_pred)\n",
    "print(diabetes_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [ 938.23786125]\n"
     ]
    }
   ],
   "source": [
    "print('Coefficients: \\n', regr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 2548.07\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean squared error: %.2f\" % mean_squared_error(diabetes_y_test, diabetes_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explained variance score: 1 is perfect prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance score: 0.47\n"
     ]
    }
   ],
   "source": [
    "print('Variance score: %.2f' % r2_score(diabetes_y_test, diabetes_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAADuCAYAAAAOR30qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBIEMAJb4L/4/ciktfwZ6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x158f57f5ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(diabetes_X_test, diabetes_y_test,  color='black')\n",
    "plt.plot(diabetes_X_test, diabetes_y_pred, color='blue', linewidth=3)\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2.2.2\n",
    "# Multivariate Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Dataset from CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataTrain = pd.read_csv(\"dataTrain.csv\")\n",
    "dataTest = pd.read_csv(\"dataTest.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets Take a Look at the Training Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature(K)</th>\n",
       "      <th>Pressure(ATM)</th>\n",
       "      <th>CompressibilityFactor(Z)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>303.230</td>\n",
       "      <td>23.434</td>\n",
       "      <td>0.725550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>313.345</td>\n",
       "      <td>26.435</td>\n",
       "      <td>0.752416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>323.345</td>\n",
       "      <td>29.344</td>\n",
       "      <td>0.778906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>383.345</td>\n",
       "      <td>25.876</td>\n",
       "      <td>0.912745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>393.678</td>\n",
       "      <td>28.344</td>\n",
       "      <td>0.939472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>363.678</td>\n",
       "      <td>27.843</td>\n",
       "      <td>0.869871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>373.789</td>\n",
       "      <td>26.567</td>\n",
       "      <td>0.891595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>273.100</td>\n",
       "      <td>24.675</td>\n",
       "      <td>0.806677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>313.100</td>\n",
       "      <td>24.675</td>\n",
       "      <td>0.888395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temperature(K)  Pressure(ATM)  CompressibilityFactor(Z)\n",
       "0         303.230         23.434                  0.725550\n",
       "1         313.345         26.435                  0.752416\n",
       "2         323.345         29.344                  0.778906\n",
       "3         383.345         25.876                  0.912745\n",
       "4         393.678         28.344                  0.939472\n",
       "5         363.678         27.843                  0.869871\n",
       "6         373.789         26.567                  0.891595\n",
       "7         273.100         24.675                  0.806677\n",
       "8         313.100         24.675                  0.888395"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataTrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Test Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature(K)</th>\n",
       "      <th>Pressure(ATM)</th>\n",
       "      <th>CompressibilityFactor(Z)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>333.123</td>\n",
       "      <td>27.343</td>\n",
       "      <td>0.798995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>343.670</td>\n",
       "      <td>25.343</td>\n",
       "      <td>0.820853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>353.340</td>\n",
       "      <td>29.343</td>\n",
       "      <td>0.847894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>373.789</td>\n",
       "      <td>26.567</td>\n",
       "      <td>0.891595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temperature(K)  Pressure(ATM)  CompressibilityFactor(Z)\n",
       "0         333.123         27.343                  0.798995\n",
       "1         343.670         25.343                  0.820853\n",
       "2         353.340         29.343                  0.847894\n",
       "3         373.789         26.567                  0.891595"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataTest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Train & Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.798995\n",
      "1    0.820853\n",
      "2    0.847894\n",
      "3    0.891595\n",
      "Name: CompressibilityFactor(Z), dtype: float64\n"
     ]
    }
   ],
   "source": [
    "x_train = dataTrain[['Temperature(K)', 'Pressure(ATM)']]#.reshape(-1,2)\n",
    "#x_train = x_train_df.values\n",
    "#x_train = x_train.reshape(-1,2)\n",
    "y_train = dataTrain['CompressibilityFactor(Z)']\n",
    "#y_train = y_train_df.values\n",
    "x_test = dataTest[['Temperature(K)', 'Pressure(ATM)']]#.reshape(-1,2)\n",
    "y_test = dataTest['CompressibilityFactor(Z)']\n",
    "print(x_train[:,:2])\n",
    "#plt.plot(y_train, y_train)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Defining and Training The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'slice'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-578b0c8f7a03>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mclf_linear\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf_linear\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\workshop\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2137\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2138\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2139\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2141\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\workshop\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2144\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2145\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2146\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2148\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\workshop\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1838\u001b[0m         \u001b[1;34m\"\"\"Return the cached item, item represents a label indexer.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1839\u001b[0m         \u001b[0mcache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_item_cache\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1840\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1841\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'slice'"
     ]
    }
   ],
   "source": [
    "clf_linear = linear_model.LinearRegression()\n",
    "model = clf_linear.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Predicting Values for the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.8268747   0.85623869  0.84524919  0.8950218 ]\n"
     ]
    }
   ],
   "source": [
    "print (model.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2.3\n",
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference to the SVM Algorithm: https://www.youtube.com/watch?v=1NxnPkZM9bc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.3.1\n",
    "## The Iris Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Code source: Gaël Varoquaux\n",
    "# Modified for documentation by Jaques Grobler\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # we only take the first two features.\n",
    "y = iris.target\n",
    "\n",
    "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "\n",
    "plt.figure(2, figsize=(8, 6))\n",
    "plt.clf()\n",
    "\n",
    "# Plot the training points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Set1,\n",
    "            edgecolor='k')\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "# To getter a better understanding of interaction of the dimensions\n",
    "# plot the first three PCA dimensions\n",
    "fig = plt.figure(1, figsize=(8, 6))\n",
    "ax = Axes3D(fig, elev=-150, azim=110)\n",
    "X_reduced = PCA(n_components=3).fit_transform(iris.data)\n",
    "ax.scatter(X_reduced[:, 0], X_reduced[:, 1], X_reduced[:, 2], c=y,\n",
    "           cmap=plt.cm.Set1, edgecolor='k', s=40)\n",
    "ax.set_title(\"First three PCA directions\")\n",
    "ax.set_xlabel(\"1st eigenvector\")\n",
    "ax.w_xaxis.set_ticklabels([])\n",
    "ax.set_ylabel(\"2nd eigenvector\")\n",
    "ax.w_yaxis.set_ticklabels([])\n",
    "ax.set_zlabel(\"3rd eigenvector\")\n",
    "ax.w_zaxis.set_ticklabels([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.3.2\n",
    "## Effect of Different Kernels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, svm\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X = X[y != 0, :2]\n",
    "y = y[y != 0]\n",
    "\n",
    "n_sample = len(X)\n",
    "\n",
    "np.random.seed(0)\n",
    "order = np.random.permutation(n_sample)\n",
    "X = X[order]\n",
    "y = y[order].astype(np.float)\n",
    "\n",
    "X_train = X[:int(.9 * n_sample)]\n",
    "y_train = y[:int(.9 * n_sample)]\n",
    "X_test = X[int(.9 * n_sample):]\n",
    "y_test = y[int(.9 * n_sample):]\n",
    "\n",
    "# fit the model\n",
    "for fig_num, kernel in enumerate(('linear', 'rbf', 'poly')):\n",
    "    clf = svm.SVC(kernel=kernel, gamma=10)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    plt.figure(fig_num)\n",
    "    plt.clf()\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, zorder=10, cmap=plt.cm.Paired,\n",
    "                edgecolor='k', s=20)\n",
    "\n",
    "    # Circle out the test data\n",
    "    plt.scatter(X_test[:, 0], X_test[:, 1], s=80, facecolors='none',\n",
    "                zorder=10, edgecolor='k')\n",
    "\n",
    "    plt.axis('tight')\n",
    "    x_min = X[:, 0].min()\n",
    "    x_max = X[:, 0].max()\n",
    "    y_min = X[:, 1].min()\n",
    "    y_max = X[:, 1].max()\n",
    "\n",
    "    XX, YY = np.mgrid[x_min:x_max:200j, y_min:y_max:200j]\n",
    "    Z = clf.decision_function(np.c_[XX.ravel(), YY.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(XX.shape)\n",
    "    plt.pcolormesh(XX, YY, Z > 0, cmap=plt.cm.Paired)\n",
    "    plt.contour(XX, YY, Z, colors=['k', 'k', 'k'],\n",
    "                linestyles=['--', '-', '--'], levels=[-.5, 0, .5])\n",
    "\n",
    "    plt.title(kernel)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.3.3\n",
    "## Support Vector Machine Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import cross_validation\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # we only take the first two features.\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets take a look at the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Data into Train and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel = 'poly')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing the Output of the Network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "\n",
    "accuracy= clf.score(X_test, y_test)\n",
    "print(\"The accuracy of the network is:\", accuracy)\n",
    "print(\"Prediction for the Test set is:\")\n",
    "print( clf.predict(X_test) )\n",
    "print(\"Lets Compare it to the original target test set:\")\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.3.4\n",
    "## Support Vector Machine Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import cross_validation\n",
    "from sklearn import svm\n",
    "\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # we only take the first two features.\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "clf = svm.SVR(kernel = 'poly')\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "accuracy= clf.score(X_test, y_test)\n",
    "print(\"The accuracy of the network is:\", accuracy)\n",
    "print(\"Prediction for the Test set is:\")\n",
    "print( clf.predict(X_test) )\n",
    "print(\"Lets Compare it to the original target test set:\")\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2.4\n",
    "# Using Different Classification Methods\n",
    "## Section 2.4.1\n",
    "## Linear Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import datasets\n",
    "from sklearn import cross_validation\n",
    "\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # we only take the first two features.\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "clf = LinearRegression()\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "accuracy= clf.score(X_test, y_test)\n",
    "print(\"The accuracy of the network is:\", accuracy)\n",
    "print(\"Prediction for the Test set is:\")\n",
    "print( clf.predict(X_test) )\n",
    "print(\"Lets Compare it to the original target test set:\")\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SVC' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-137-12adc65a2861>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m classifiers = [\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m#KNeighborsClassifier(3),\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"linear\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.025\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mGaussianProcessClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mRBF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SVC' is not defined"
     ]
    }
   ],
   "source": [
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.4.2\n",
    "## Random Forest Classification:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reference: Random Forest: https://www.youtube.com/watch?v=loNcrMjYh64\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reference: ensemble methods: http://scikit-learn.org/stable/modules/ensemble.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import datasets\n",
    "from sklearn import cross_validation\n",
    "\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # we only take the first two features.\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "accuracy= clf.score(X_test, y_test)\n",
    "print(\"The accuracy of the network is:\", accuracy)\n",
    "print(\"Prediction for the Test set is:\")\n",
    "print( clf.predict(X_test) )\n",
    "print(\"Lets Compare it to the original target test set:\")\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest Parameters:\n",
    "\n",
    "The main parameters to adjust when using these methods is n_estimators and max_features. The former is the number of trees in the forest. The larger the better, but also the longer it will take to compute. In addition, note that results will stop getting significantly better beyond a critical number of trees. The latter is the size of the random subsets of features to consider when splitting a node. The lower the greater the reduction of variance, but also the greater the increase in bias. Empirical good default values are max_features=n_features for regression problems, and max_features=sqrt(n_features) for classification tasks (where n_features is the number of features in the data). Good results are often achieved when setting max_depth=None in combination with min_samples_split=2 (i.e., when fully developing the trees). Bear in mind though that these values are usually not optimal, and might result in models that consume a lot of RAM. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.4.3\n",
    "## Ada Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import datasets\n",
    "from sklearn import cross_validation\n",
    "\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # we only take the first two features.\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "clf = AdaBoostClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "accuracy= clf.score(X_test, y_test)\n",
    "print(\"The accuracy of the network is:\", accuracy)\n",
    "print(\"Prediction for the Test set is:\")\n",
    "print( clf.predict(X_test) )\n",
    "print(\"Lets Compare it to the original target test set:\")\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4.4\n",
    "## Mulit-Layer Perceptrons/ MLP / ANN (Artificial Neural Network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: ANN: https://www.youtube.com/watch?v=LCzufhtIFnY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: Scikit-learn : http://scikit-learn.org/stable/modules/neural_networks_supervised.html#multi-layer-perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import datasets\n",
    "from sklearn import cross_validation\n",
    "\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # we only take the first two features.\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "#clf = MLPClassifier(alpha=1)\n",
    "\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "accuracy= clf.score(X_test, y_test)\n",
    "print(\"The accuracy of the network is:\", accuracy)\n",
    "print(\"Prediction for the Test set is:\")\n",
    "print( clf.predict(X_test) )\n",
    "print(\"Lets Compare it to the original target test set:\")\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Section 2.5: Visiting an Example\n",
    "## Kth Nearest Network implementation using Pima-Indian Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference : Pima indian dataset:  https://github.com/LamaHamadeh/Pima-Indians-Diabetes-DataSet-UCI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### important necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('pima_indians_diabetes.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### defining the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " \n",
    "df.columns =['No_pregnant', 'Plasma_glucose', 'Blood_pres', 'Skin_thick', \n",
    "             'Serum_insu', 'BMI', 'Diabetes_func', 'Age', 'Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checking the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   No_pregnant  Plasma_glucose  Blood_pres  Skin_thick  Serum_insu   BMI  \\\n",
      "0            1              85          66          29           0  26.6   \n",
      "1            8             183          64           0           0  23.3   \n",
      "2            1              89          66          23          94  28.1   \n",
      "3            0             137          40          35         168  43.1   \n",
      "4            5             116          74           0           0  25.6   \n",
      "\n",
      "   Diabetes_func  Age  Class  \n",
      "0          0.351   31      0  \n",
      "1          0.672   32      1  \n",
      "2          0.167   21      0  \n",
      "3          2.288   33      1  \n",
      "4          0.201   30      0  \n",
      "No_pregnant         int64\n",
      "Plasma_glucose      int64\n",
      "Blood_pres          int64\n",
      "Skin_thick          int64\n",
      "Serum_insu          int64\n",
      "BMI               float64\n",
      "Diabetes_func     float64\n",
      "Age                 int64\n",
      "Class               int64\n",
      "dtype: object\n",
      "(767, 9)\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(df.dtypes)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### identify nans ( missing data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "No_pregnant       0\n",
      "Plasma_glucose    0\n",
      "Blood_pres        0\n",
      "Skin_thick        0\n",
      "Serum_insu        0\n",
      "BMI               0\n",
      "Diabetes_func     0\n",
      "Age               0\n",
      "Class             0\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def num_missing(x):\n",
    "  return sum(x.isnull())\n",
    "#Applying per column:\n",
    "print (\"Missing values per column:\")\n",
    "print (df.apply(num_missing, axis=0),'\\n') #no nans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the K nearest neighbour classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: kNN Algorithm: https://www.youtube.com/watch?v=UqYde-LULfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: kNN Sklearn : http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split the data into training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = np.array(df.drop(['Class'], axis = 1))\n",
    "y = np.array(df['Class'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size =0.5,random_state = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply the knn method:\n",
    "\n",
    "this is basically a binary classifier detecting diabetes or not based on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Knn = DecisionTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of the model is:  0.739583333333\n"
     ]
    }
   ],
   "source": [
    "accuracy = Knn.score(X_test, y_test)#this to see how accurate the algorithm is in terms \n",
    "#of defining the diabetes to be either 1 or 0\n",
    "print('accuracy of the model is: ', accuracy) #0.73"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting and visualisation (focus on only two features from the dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X1 = np.array(df[['Plasma_glucose','Age']]) #choose only two features\n",
    "Y = np.array(df['Class']) #the label of the dataset\n",
    "\n",
    "h = .02  # step size in the mesh\n",
    " \n",
    "# Create color maps using hex_colors\n",
    "cmap_light = ListedColormap(['#FFAAAA', '#AAAAFF'])\n",
    "cmap_bold = ListedColormap(['#FF0000', '#0000FF'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply Neighbours Classifier and fit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split (X1, y, test_size=0.5, random_state = 7)\n",
    "Knn = KNeighborsClassifier(n_neighbors = 15)\n",
    "Knn.fit(X1, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the decision boundary. For that, we will assign a color to each (this portion might take a while to run. please be patient) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# point in the mesh [x_min, m_max]x[y_min, y_max].\n",
    "x_min, x_max = X1[:, 0].min() - 1, X1[:, 0].max() + 1\n",
    "y_min, y_max = X1[:, 1].min() - 1, X1[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "Z = Knn.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure()\n",
    "plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "# Plot also the training points\n",
    "plt.scatter(X1[:, 0], X1[:, 1], c=y, cmap=cmap_bold)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.xlabel('Plasma glucose concentration a 2 hours in an oral glucose tolerance test')\n",
    "plt.ylabel('Age')\n",
    "plt.title('K = 15')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The part of code we actually need in a nuthsell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#important necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "#-------------------\n",
    "\n",
    "#loading the dataframe\n",
    "df = pd.read_csv('pima_indians_diabetes.txt')\n",
    "\n",
    "#-------------------\n",
    "\n",
    "#defining the columns \n",
    "df.columns =['No_pregnant', 'Plasma_glucose', 'Blood_pres', 'Skin_thick', \n",
    "             'Serum_insu', 'BMI', 'Diabetes_func', 'Age', 'Class']\n",
    "\n",
    "X = np.array(df.drop(['Class'], axis = 1))\n",
    "y = np.array(df['Class'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size =0.5, \n",
    "                                                    random_state = 7)\n",
    "Knn = KNeighborsClassifier(n_neighbors = 2)\n",
    "\n",
    "#train the data\n",
    "Knn.fit(X_train,y_train)\n",
    "\n",
    "accuracy = Knn.score(X_test, y_test)#this to see how accurate the algorithm is in terms \n",
    "#of defining the diabetes to be either 1 or 0\n",
    "print('accuracy of the model is: ', accuracy) #0.73\n",
    "\n",
    "predictions = Knn.predict(X_test)\n",
    "print('predictions generated by the knn:')\n",
    "print(predictions)\n",
    "print('the actual diabetes ground truth:')\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2.6\n",
    "# Visualizing effects of different classifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "h = .02  # step size in the mesh\n",
    "\n",
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\", \"QDA\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "X, y = make_classification(n_features=2, n_redundant=0, n_informative=2,\n",
    "                           random_state=1, n_clusters_per_class=1)\n",
    "rng = np.random.RandomState(2)\n",
    "X += 2 * rng.uniform(size=X.shape)\n",
    "linearly_separable = (X, y)\n",
    "\n",
    "datasets = [make_moons(noise=0.3, random_state=0),\n",
    "            make_circles(noise=0.2, factor=0.5, random_state=1),\n",
    "            linearly_separable\n",
    "            ]\n",
    "\n",
    "figure = plt.figure(figsize=(27, 9))\n",
    "i = 1\n",
    "# iterate over datasets\n",
    "for ds_cnt, ds in enumerate(datasets):\n",
    "    # preprocess dataset, split into training and test part\n",
    "    X, y = ds\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(X, y, test_size=.4, random_state=42)\n",
    "\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "\n",
    "    # just plot the dataset first\n",
    "    cm = plt.cm.RdBu\n",
    "    cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "    ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "    if ds_cnt == 0:\n",
    "        ax.set_title(\"Input data\")\n",
    "    # Plot the training points\n",
    "    ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright,\n",
    "               edgecolors='k')\n",
    "    # and testing points\n",
    "    ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, alpha=0.6,\n",
    "               edgecolors='k')\n",
    "    ax.set_xlim(xx.min(), xx.max())\n",
    "    ax.set_ylim(yy.min(), yy.max())\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    i += 1\n",
    "\n",
    "    # iterate over classifiers\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_test, y_test)\n",
    "\n",
    "        # Plot the decision boundary. For that, we will assign a color to each\n",
    "        # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "        if hasattr(clf, \"decision_function\"):\n",
    "            Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "        else:\n",
    "            Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "\n",
    "        # Put the result into a color plot\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        ax.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n",
    "\n",
    "        # Plot also the training points\n",
    "        ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright,\n",
    "                   edgecolors='k')\n",
    "        # and testing points\n",
    "        ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright,\n",
    "                   edgecolors='k', alpha=0.6)\n",
    "\n",
    "        ax.set_xlim(xx.min(), xx.max())\n",
    "        ax.set_ylim(yy.min(), yy.max())\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "        if ds_cnt == 0:\n",
    "            ax.set_title(name)\n",
    "        ax.text(xx.max() - .3, yy.min() + .3, ('%.2f' % score).lstrip('0'),\n",
    "                size=15, horizontalalignment='right')\n",
    "        i += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
